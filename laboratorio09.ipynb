{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMnTLNrwixd8"
      },
      "source": [
        "# Ejercicio de programación Regresión Lineal Multiple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 316,
      "metadata": {
        "id": "GGF64D8mixd-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Computacion vectorial y cientifica para python\n",
        "import numpy as np\n",
        "\n",
        "# Librerias para graficación (trazado de gráficos)\n",
        "from matplotlib import pyplot\n",
        "from mpl_toolkits.mplot3d import Axes3D  # Necesario para graficar superficies 3D\n",
        "from google.colab import drive\n",
        "# llama a matplotlib a embeber graficas dentro de los cuadernillos\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOqT_Rmj2Ekl",
        "outputId": "3b320219-7e61-4d79-f57a-919a1451a29d"
      },
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEoJidm7ixeA"
      },
      "source": [
        "## 2 Regresión lineal con multiples variables\n",
        "\n",
        "Se implementa la regresion lineal multivariable para predecir el precio de las casas. El archivo `Datasets/ex1data2.txt` contiene un conjunto de entrenamiento de precios de casas en Portland, Oregon. La primera columna es el tamaño de la casa en metros cuadrados, la segunda columna es el numero de cuartos, y la tercera columna es el precio de la casa. \n",
        "\n",
        "<a id=\"section4\"></a>\n",
        "### 2.1 Normalización de caracteristicas\n",
        "\n",
        "Al visualizar los datos se puede observar que las caracteristicas tienen diferentes magnitudes, por lo cual se debe transformar cada valor en una escala de valores similares, esto con el fin de que el descenso por el gradiente pueda converger mas rapidamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 318,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NtHZuZoixeA",
        "outputId": "8bce037b-e78d-4ec4-b3f0-37dfd3552c93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6.81 3.79 3.28 10.22 4.22 6.5 2.93 4.7 0.28 1.93 4.13 7.2 3.6 2.53 0.24\n",
            " 0.97 0.41 3.54 4.16 6.04 4.18 3.84 0.06 0.47 5.38 5.65 5.32 1.87 0.13\n",
            " 3.12 0.11 4.34 0.35 0.65 0.07 0.08 0.49 0.3 2.66 0.48 5.33 2.67 0.13 0.36\n",
            " 3.96 1.91 1.1 1.2 3.08 2.69 0.14 2.54 2.13 0.81 0.38 0.44 2.12 3.15 1.25\n",
            " 0.0 0.04 0.08 2.23 2.47 0.04 3.28 0.38 0.01 1.69 0.13 3.0 0.02 4.36 1.98\n",
            " 0.1 3.81 0.06 2.49 0.05 1.58 3.14 0.13 0.0 0.13 0.66 2.73 3.63 2.69 0.0\n",
            " 0.24 0.98 0.22 0.14 1.45 1.31 0.7 2.42 0.0 0.06 0.6 0.01 0.0 0.35 0.08\n",
            " 1.4 1.42 1.39 1.27 0.24 0.87 0.0 0.07 0.08 0.17 0.19 0.94 0.0 0.06 0.21\n",
            " 0.28 0.11 1.6 0.17 0.05 1.03 0.25 1.69 0.16 0.08 2.06 1.49 1.29 0.06 0.09\n",
            " 0.87 2.87 0.0 0.02 0.03 0.07 0.07 0.87 0.16 0.83 0.78 0.28 2.33 0.17 4.35\n",
            " 0.0 2.02 1.36 0.07 0.16 1.81 0.21 1.97 0.07 0.11 0.1 4.13 0.91 0.99 0.95\n",
            " 0.94 0.0 0.24 0.0 1.87 2.0 1.01 0.03 2.78 2.11 1.09 0.08 1.03 0.2 0.01\n",
            " 3.61 0.0 0.83 1.27 1.57 0.03 0.95 2.2 1.89 0.44 0.13 1.7 0.05 0.01 0.0\n",
            " 0.0 1.08 0.0 0.16 0.06 0.15 1.11 0.02 0.8 0.0 0.07 0.29 0.01 0.09 1.54\n",
            " 0.12 0.01 0.0 0.89 4.87 1.52 0.12 0.0 0.09 0.04 0.44 0.06 0.04 0.02 0.0\n",
            " 0.02 1.32 0.08 0.06 0.13 0.0 1.15 0.89 0.22 1.1 1.44 0.07 0.01 0.01 0.0\n",
            " 0.01 0.03 4.1 0.08 0.19 0.02 0.46 0.01 0.01 1.05 0.13 1.61 0.08 0.14 0.26\n",
            " 1.38 0.01 0.0 0.0 0.11 0.03 0.72 0.07 0.1 0.05 0.83 0.0 0.0 0.62 0.04 0.2\n",
            " 0.18 0.57 0.04 0.58 0.02 0.31 1.57 0.0 0.01 0.11 0.09 1.76 0.03 0.37 2.1\n",
            " 0.05 0.01 0.0 0.04 0.04 0.03 0.9 0.16 0.51 0.1 0.64 0.12 2.46 0.07 0.92\n",
            " 0.05 0.0 0.06 0.08 1.07 0.01 0.13 2.62 0.06 0.0 0.31 3.77 0.1 0.03 1.12\n",
            " 1.05 0.22 0.54 0.81 0.41 0.73 0.1 0.27 0.0 0.47 0.1 0.0 0.0 0.59 0.14\n",
            " 0.21 1.54 0.0 0.04 1.38 0.27 0.08 3.67 0.01 0.0 0.55 0.06 0.0 0.4 0.15\n",
            " 0.66 0.05 0.64 0.05 0.46 0.15 0.03 0.0 0.0 0.1 0.46 0.03 0.06 0.0 0.07\n",
            " 0.05 0.12 0.1 0.01 0.02 0.02 0.0 0.01 0.05 0.27 0.12 1.75 0.03 1.42 0.02\n",
            " 0.73 0.04 0.02 0.04 0.01 0.0 0.1 3.44 0.03 0.33 0.17 0.06 0.0 2.55 0.02\n",
            " 0.59 0.05 0.19 0.0 0.48 0.74 0.0 0.73 0.82 0.0 0.01 2.32 0.12 0.57 0.76\n",
            " 0.03 0.05 0.05 0.06 0.0 0.02 0.46 0.31 2.78 0.77 0.0 0.12 0.0 3.18 0.0\n",
            " 2.35 0.12 0.07 0.8 0.04 3.19 0.01 0.09 0.93 0.1 0.0]\n",
            "[[29.08 3.58 6.81 0.77]\n",
            " [15.85 12.88 3.79 3.31]\n",
            " [15.75 11.01 3.28 2.96]\n",
            " ...\n",
            " [1.18 0.87 0.93 0.2]\n",
            " [1.52 1.08 0.1 0.47]\n",
            " [1.86 1.02 0.0 0.29]]\n"
          ]
        }
      ],
      "source": [
        "# Cargar datos\n",
        "data = pd.read_csv((\"/content/drive/MyDrive/dataset/vgsales.csv\"),delimiter=',', skiprows=1)\n",
        "data= np.array(data)\n",
        "X = np.column_stack((data[:431,2:2],data[:431,4:4],data[:431,6:10]))\n",
        "\n",
        "\n",
        "y = data[:431, 8]\n",
        "m = y.size\n",
        "\n",
        "print(y)\n",
        "print(X)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def CambioDatos(x,y):\n",
        " \n",
        "\n",
        "  for i in range(m):\n",
        "    for j in range(4):\n",
        "      if x[i,j]== \"DS\":\n",
        "        x[i,j]= 1\n",
        "      if x[i,j]== \"PS2\":\n",
        "        x[i,j]= 2\n",
        "      if x[i,j]== \"PS3\":\n",
        "        x[i,j]= 3\n",
        "      if x[i,j]== \"Wii\":\n",
        "        x[i,j]= 4\n",
        "      if x[i,j]== \"X360\":\n",
        "        x[i,j]= 5\n",
        "      if x[i,j]== \"NES\":\n",
        "        x[i,j]= 6\n",
        "      if x[i,j]== \"GB\":\n",
        "        x[i,j]= 7\n",
        "      if x[i,j]== \"SNES\":\n",
        "        x[i,j]= 8\n",
        "      if x[i,j]== \"PS4\":\n",
        "        x[i,j]= 6\n",
        "      if x[i,j]== \".3DS\":\n",
        "        x[i,j]= 7\n",
        "      if x[i,j]== \"P.D\":\n",
        "        x[i,j]= 8\n",
        "      if x[i,j]== \"N64\":\n",
        "        x[i,j]= 8\n",
        "      if x[i,j]== \"PC\":\n",
        "        x[i,j]= 9\n",
        "      if x[i,j]== \"PSP\":\n",
        "        x[i,j]= 10\n",
        "      if x[i,j]== \"3DS\":\n",
        "        x[i,j]= 11\n",
        "      if x[i,j]== \"GBA\":\n",
        "        x[i,j]= 12\n",
        "      if x[i,j]== \"GC\":\n",
        "        x[i,j]= 13\n",
        "      if x[i,j]== \"PS\":\n",
        "        x[i,j]= 14\n",
        "      if x[i,j]== \"SAT\":\n",
        "        x[i,j]= 15\n",
        "      if x[i,j]== \"XB\":\n",
        "        x[i,j]= 16\n",
        "      if x[i,j]== \"PSV\":\n",
        "        x[i,j]= 17\n",
        "      if x[i,j]== \"XOne\":\n",
        "        x[i,j]= 18\n",
        "      if x[i,j]== \"DC\":\n",
        "        x[i,j]= 19\n",
        "      if x[i,j]== \"WiiU\":\n",
        "        x[i,j]= 20\n",
        "      if x[i,j]== \"GEN\":\n",
        "        x[i,j]= 21\n",
        "      if x[i,j]== \"SDC\":\n",
        "        x[i,j]= 22\n",
        "      if x[i,j]== \"Action\":\n",
        "        x[i,j]= 1\n",
        "      if x[i,j]== \"Sports\":\n",
        "        x[i,j]= 2\n",
        "      if x[i,j]== \"Racing\":\n",
        "        x[i,j]= 3\n",
        "      if x[i,j]== \"Role-Playing\":\n",
        "        x[i,j]= 4\n",
        "      if x[i,j]== \"Shooter\":\n",
        "        x[i,j]= 5\n",
        "      if x[i,j]== \"Platform\":\n",
        "        x[i,j]= 6\n",
        "      if x[i,j]== \"Puzzle\":\n",
        "        x[i,j]= 7\n",
        "      if x[i,j]== \"Fighting\":\n",
        "        x[i,j]= 8\n",
        "      if x[i,j]== \"Simulation\":\n",
        "        x[i,j]= 9\n",
        "      if x[i,j]== \"Adventure\":\n",
        "        x[i,j]= 10\n",
        "      if x[i,j]== \"Misc\":\n",
        "        x[i,j]= 11\n",
        "      if x[i,j]== \"Strategy\":\n",
        "        x[i,j]= 12\n",
        "      if x[i,j]== \"N/A\":\n",
        "        x[i,j]= 0\n",
        "\n",
        "      \n",
        "\n",
        "\n",
        "CambioDatos(X,y)\n",
        "X=np.array(X).astype(float)"
      ],
      "metadata": {
        "id": "ru_L23qz4vWy"
      },
      "execution_count": 319,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mGD_G8KqNhTv"
      },
      "execution_count": 319,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aidItZrFixeB"
      },
      "source": [
        "La desviación estándar es una forma de medir cuánta variación hay en el rango de valores de una característica en particular (la mayoría de los puntos caeran en un rango de ± 2 en relación a la desviaciones estándar de la media); esta es una alternativa a tomar el rango de valores (max-min). En `numpy`, se puede usar la función `std` para calcular la desviacion estandar. \n",
        "\n",
        "Por ejemplo, la caracteristica`X[:, 0]` contiene todos los valores de $x_1$ (tamaño de las casas) en el conjunto de entrenamiento, entonces `np.std(X[:, 0])` calcula la desviacion estandar de los tamaños de las casas.\n",
        "En el momento en que se llama a la función `featureNormalize`, la columna adicional de unos correspondiente a $ x_0 = 1 $ aún no se ha agregado a $ X $. \n",
        "\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "**Notas para la implementación:** Cuando se normalize una caracteristica, es importante almacenar los valores usados para la normalización - el valor de la media y el valor de la desviación estandar usado para los calculos. Despues de aprender los parametros del modelo, se deseara predecir los precios de casas que no se han visto antes. Dado un nuevo valor de x (area del living room y el numero de dormitorios), primero se debe normalizar x usando la media y la desviacion estandar que se empleo anteriormente en el conjunto de entrenamiento para entrenar el modelo.\n",
        "</div>\n",
        "<a id=\"featureNormalize\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 320,
      "metadata": {
        "id": "ItYnCBRtixeC"
      },
      "outputs": [],
      "source": [
        "def  featureNormalize(X):\n",
        "    X_norm = X.copy()\n",
        "    mu = np.zeros(X.shape[1])\n",
        "    sigma = np.zeros(X.shape[1])\n",
        "\n",
        "    mu = np.mean(X, axis = 0)\n",
        "    sigma = np.std(X, axis = 0)\n",
        "    X_norm = (X - mu) / sigma\n",
        "    \n",
        "    return X_norm, mu, sigma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 321,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98uxsj3cixeC",
        "outputId": "cf3f96d8-a530-4eaf-e7a0-42a25d49bc3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[29.08  3.58  6.81  0.77]\n",
            "[15.85 12.88  3.79  3.31]\n",
            "[15.75 11.01  3.28  2.96]\n",
            "[11.27  8.89 10.22  1.  ]\n",
            "[23.2   2.26  4.22  0.58]\n",
            "[11.38  9.23  6.5   2.9 ]\n",
            "[14.03  9.2   2.93  2.85]\n",
            "[14.59  7.06  4.7   2.26]\n",
            "[26.93  0.63  0.28  0.47]\n",
            "[ 9.07 11.    1.93  2.75]\n",
            "[9.81 7.57 4.13 1.92]\n",
            "[9.   6.18 7.2  0.71]\n",
            "[8.94 8.03 3.6  2.15]\n",
            "[9.09 8.59 2.53 1.79]\n",
            "[14.97  4.94  0.24  1.67]\n",
            "[7.01 9.27 0.97 4.14]\n",
            "[ 9.43  0.4   0.41 10.57]\n",
            "[12.78  3.75  3.54  0.55]\n",
            "[4.75 9.26 4.16 2.05]\n",
            "[6.42 4.52 6.04 1.37]\n",
            "[10.83  2.71  4.18  0.42]\n",
            "[9.54 3.44 3.84 0.46]\n",
            "[9.63 5.31 0.06 1.38]\n",
            "[8.41 5.49 0.47 1.78]\n",
            "[6.06 3.9  5.38 0.5 ]\n",
            "[5.57 3.28 5.65 0.82]\n",
            "[3.44 5.36 5.32 1.18]\n",
            "[6.85 5.09 1.87 1.16]\n",
            "[9.03 4.28 0.13 1.32]\n",
            "[5.89 5.04 3.12 0.59]\n",
            "[9.67 3.73 0.11 1.13]\n",
            "[5.17 4.05 4.34 0.79]\n",
            "[5.77 5.81 0.35 2.31]\n",
            "[4.99 5.88 0.65 2.52]\n",
            "[8.25 4.3  0.07 1.12]\n",
            "[8.52 3.63 0.08 1.29]\n",
            "[5.54 5.82 0.49 1.62]\n",
            "[6.99 4.51 0.3  1.3 ]\n",
            "[6.75 2.61 2.66 1.02]\n",
            "[5.98 4.44 0.48 1.83]\n",
            "[2.55 3.52 5.33 0.88]\n",
            "[4.74 3.91 2.67 0.89]\n",
            "[7.97 2.83 0.13 1.21]\n",
            "[3.8  5.81 0.36 2.02]\n",
            "[4.4  2.77 3.96 0.77]\n",
            "[6.91 2.85 1.91 0.23]\n",
            "[3.01 0.01 1.1  7.53]\n",
            "[6.16 3.4  1.2  0.76]\n",
            "[4.23 3.37 3.08 0.65]\n",
            "[6.16 2.04 2.69 0.29]\n",
            "[6.76 3.1  0.14 1.03]\n",
            "[4.02 3.87 2.54 0.52]\n",
            "[4.89 2.99 2.13 0.78]\n",
            "[2.96 4.88 0.81 2.12]\n",
            "[4.99 3.69 0.38 1.63]\n",
            "[4.76 3.76 0.44 1.62]\n",
            "[5.99 2.15 2.12 0.29]\n",
            "[4.34 2.65 3.15 0.35]\n",
            "[5.08 3.11 1.25 0.98]\n",
            "[6.05 3.15 0.   1.07]\n",
            "[6.72 2.63 0.04 0.82]\n",
            "[7.03 1.98 0.08 0.78]\n",
            "[5.55 1.94 2.23 0.15]\n",
            "[3.66 3.07 2.47 0.63]\n",
            "[6.63 2.36 0.04 0.73]\n",
            "[3.01 2.47 3.28 0.96]\n",
            "[4.09 3.73 0.38 1.38]\n",
            "[5.84 2.89 0.01 0.78]\n",
            "[3.88 3.42 1.69 0.5 ]\n",
            "[5.91 2.38 0.13 0.9 ]\n",
            "[4.36 1.71 3.   0.23]\n",
            "[5.58 2.83 0.02 0.77]\n",
            "[2.01 2.32 4.36 0.41]\n",
            "[4.46 1.88 1.98 0.7 ]\n",
            "[5.03 2.86 0.1  0.85]\n",
            "[3.54 1.24 3.81 0.18]\n",
            "[1.11 6.06 0.06 1.26]\n",
            "[1.79 3.53 2.49 0.68]\n",
            "[6.82 1.53 0.05 0.08]\n",
            "[3.81 2.3  1.58 0.73]\n",
            "[2.91 1.86 3.14 0.43]\n",
            "[1.06 5.05 0.13 2.01]\n",
            "[0.98 6.42 0.   0.71]\n",
            "[5.8  2.01 0.13 0.15]\n",
            "[2.58 3.9  0.66 0.91]\n",
            "[2.91 2.07 2.73 0.33]\n",
            "[2.28 1.72 3.63 0.23]\n",
            "[2.82 1.78 2.69 0.55]\n",
            "[7.28 0.45 0.   0.08]\n",
            "[2.9  2.83 0.24 1.75]\n",
            "[3.66 2.42 0.98 0.64]\n",
            "[2.93 3.29 0.22 1.23]\n",
            "[2.8  3.3  0.14 1.37]\n",
            "[4.1  1.89 1.45 0.16]\n",
            "[3.78 2.17 1.31 0.31]\n",
            "[5.39 1.18 0.7  0.19]\n",
            "[3.24 1.35 2.42 0.43]\n",
            "[4.79 1.9  0.   0.69]\n",
            "[4.46 2.13 0.06 0.69]\n",
            "[3.83 2.19 0.6  0.7 ]\n",
            "[4.52 2.09 0.01 0.67]\n",
            "[3.51 3.03 0.   0.73]\n",
            "[2.85 2.93 0.35 1.1 ]\n",
            "[3.27 2.83 0.08 1.02]\n",
            "[3.27 2.22 1.4  0.29]\n",
            "[3.68 1.75 1.42 0.28]\n",
            "[4.41 1.04 1.39 0.22]\n",
            "[3.13 2.07 1.27 0.49]\n",
            "[2.47 3.15 0.24 1.1 ]\n",
            "[4.12 1.77 0.87 0.19]\n",
            "[4.14 2.21 0.   0.56]\n",
            "[0.78 4.32 0.07 1.73]\n",
            "[2.71 3.02 0.08 1.09]\n",
            "[2.93 2.75 0.17 0.99]\n",
            "[2.77 2.8  0.19 1.06]\n",
            "[3.23 2.35 0.94 0.3 ]\n",
            "[3.5  2.64 0.   0.67]\n",
            "[4.15 1.92 0.06 0.64]\n",
            "[3.27 2.25 0.21 1.  ]\n",
            "[3.1  2.3  0.28 1.04]\n",
            "[0.84 4.32 0.11 1.42]\n",
            "[1.67 2.78 1.6  0.62]\n",
            "[2.79 2.61 0.17 1.03]\n",
            "[0.79 4.29 0.05 1.47]\n",
            "[3.25 1.84 1.03 0.47]\n",
            "[2.55 2.71 0.25 1.05]\n",
            "[3.74 0.93 1.69 0.14]\n",
            "[2.64 2.56 0.16 1.14]\n",
            "[4.98 1.3  0.08 0.07]\n",
            "[2.57 1.58 2.06 0.21]\n",
            "[3.64 1.2  1.49 0.07]\n",
            "[2.55 1.56 1.29 0.99]\n",
            "[4.34 1.35 0.06 0.61]\n",
            "[3.7  1.97 0.09 0.57]\n",
            "[4.01 1.26 0.87 0.17]\n",
            "[2.47 0.83 2.87 0.12]\n",
            "[0.07 6.21 0.   0.  ]\n",
            "[3.11 2.8  0.02 0.33]\n",
            "[3.92 1.78 0.03 0.51]\n",
            "[4.05 1.62 0.07 0.49]\n",
            "[3.54 1.9  0.07 0.6 ]\n",
            "[2.45 2.01 0.87 0.72]\n",
            "[4.47 1.2  0.16 0.19]\n",
            "[2.63 1.74 0.83 0.83]\n",
            "[3.18 1.83 0.78 0.24]\n",
            "[2.41 2.28 0.28 1.01]\n",
            "[1.88 0.   2.33 1.74]\n",
            "[2.8  2.05 0.17 0.9 ]\n",
            "[0.66 0.69 4.35 0.15]\n",
            "[3.66 1.63 0.   0.53]\n",
            "[1.88 1.47 2.02 0.45]\n",
            "[2.26 1.89 1.36 0.23]\n",
            "[3.13 1.94 0.07 0.58]\n",
            "[2.49 2.05 0.16 0.96]\n",
            "[2.97 0.69 1.81 0.11]\n",
            "[2.54 1.95 0.21 0.87]\n",
            "[2.95 0.6  1.97 0.04]\n",
            "[3.28 1.65 0.07 0.55]\n",
            "[2.7  1.91 0.11 0.8 ]\n",
            "[2.99 1.92 0.1  0.51]\n",
            "[0.47 0.57 4.13 0.34]\n",
            "[3.14 1.24 0.91 0.2 ]\n",
            "[2.62 1.64 0.99 0.23]\n",
            "[3.21 1.11 0.95 0.2 ]\n",
            "[3.18 1.24 0.94 0.09]\n",
            "[2.72 1.87 0.   0.84]\n",
            "[2.07 2.29 0.24 0.82]\n",
            "[1.97 2.51 0.   0.94]\n",
            "[1.74 1.24 1.87 0.52]\n",
            "[2.18 0.96 2.   0.2 ]\n",
            "[3.02 1.12 1.01 0.16]\n",
            "[3.13 1.71 0.03 0.44]\n",
            "[1.62 0.77 2.78 0.14]\n",
            "[1.92 1.08 2.11 0.17]\n",
            "[3.33 0.79 1.09 0.06]\n",
            "[3.1  1.56 0.08 0.51]\n",
            "[1.22 2.48 1.03 0.52]\n",
            "[2.3  2.46 0.2  0.28]\n",
            "[4.26 0.26 0.01 0.71]\n",
            "[0.65 0.75 3.61 0.2 ]\n",
            "[2.43 2.15 0.   0.62]\n",
            "[2.93 1.25 0.83 0.2 ]\n",
            "[2.32 1.3  1.27 0.31]\n",
            "[2.49 0.98 1.57 0.15]\n",
            "[1.08 3.48 0.03 0.58]\n",
            "[1.9  1.83 0.95 0.49]\n",
            "[2.1  0.74 2.2  0.11]\n",
            "[0.96 2.02 1.89 0.28]\n",
            "[1.64 2.48 0.44 0.58]\n",
            "[1.98 2.23 0.13 0.8 ]\n",
            "[2.71 0.61 1.7  0.11]\n",
            "[3.59 1.11 0.05 0.38]\n",
            "[3.21 1.53 0.01 0.38]\n",
            "[3.22 1.69 0.   0.2 ]\n",
            "[3.81 0.63 0.   0.68]\n",
            "[1.96 1.43 1.08 0.65]\n",
            "[2.66 2.01 0.   0.41]\n",
            "[1.7  2.02 0.16 1.21]\n",
            "[0.6  3.29 0.06 1.13]\n",
            "[3.4  1.3  0.15 0.22]\n",
            "[2.05 1.16 1.11 0.73]\n",
            "[3.42 1.38 0.02 0.2 ]\n",
            "[2.59 1.06 0.8  0.57]\n",
            "[2.79 1.89 0.   0.33]\n",
            "[3.36 1.36 0.07 0.21]\n",
            "[3.06 1.18 0.29 0.46]\n",
            "[3.49 0.01 0.01 1.48]\n",
            "[3.39 1.03 0.09 0.44]\n",
            "[1.85 1.2  1.54 0.37]\n",
            "[2.31 1.73 0.12 0.78]\n",
            "[3.98 0.26 0.01 0.66]\n",
            "[2.89 1.54 0.   0.46]\n",
            "[2.91 0.99 0.89 0.1 ]\n",
            "[0.   0.   4.87 0.  ]\n",
            "[2.62 0.6  1.52 0.1 ]\n",
            "[2.74 1.36 0.12 0.63]\n",
            "[2.56 1.68 0.   0.59]\n",
            "[1.91 2.   0.09 0.83]\n",
            "[0.57 3.14 0.04 1.07]\n",
            "[2.57 1.57 0.44 0.21]\n",
            "[0.28 3.75 0.06 0.69]\n",
            "[2.99 1.31 0.04 0.41]\n",
            "[2.36 2.1  0.02 0.25]\n",
            "[1.73 2.19 0.   0.79]\n",
            "[3.05 1.41 0.02 0.2 ]\n",
            "[1.87 1.12 1.32 0.37]\n",
            "[1.94 1.95 0.08 0.7 ]\n",
            "[2.08 2.04 0.06 0.47]\n",
            "[2.29 1.97 0.13 0.24]\n",
            "[3.06 1.12 0.   0.44]\n",
            "[2.42 0.91 1.15 0.13]\n",
            "[2.6  0.99 0.89 0.13]\n",
            "[1.89 1.99 0.22 0.48]\n",
            "[1.78 1.39 1.1  0.3 ]\n",
            "[1.55 1.15 1.44 0.43]\n",
            "[1.78 1.87 0.07 0.82]\n",
            "[3.19 0.92 0.01 0.42]\n",
            "[4.18 0.26 0.01 0.08]\n",
            "[4.21 0.24 0.   0.05]\n",
            "[3.63 0.24 0.01 0.61]\n",
            "[2.71 1.51 0.03 0.23]\n",
            "[0.2  0.14 4.1  0.02]\n",
            "[1.96 1.69 0.08 0.74]\n",
            "[1.54 1.94 0.19 0.77]\n",
            "[2.71 1.29 0.02 0.43]\n",
            "[2.55 1.11 0.46 0.33]\n",
            "[2.67 1.35 0.01 0.39]\n",
            "[2.66 1.29 0.01 0.46]\n",
            "[0.1  2.39 1.05 0.86]\n",
            "[2.82 1.05 0.13 0.4 ]\n",
            "[2.19 0.5  1.61 0.08]\n",
            "[2.03 1.79 0.08 0.47]\n",
            "[1.73 1.73 0.14 0.75]\n",
            "[3.03 0.91 0.26 0.13]\n",
            "[2.2  0.58 1.38 0.17]\n",
            "[0.92 2.93 0.01 0.46]\n",
            "[2.75 1.18 0.   0.37]\n",
            "[4.   0.26 0.   0.05]\n",
            "[2.51 1.27 0.11 0.41]\n",
            "[2.64 1.2  0.03 0.39]\n",
            "[2.11 1.11 0.72 0.3 ]\n",
            "[2.23 1.34 0.07 0.61]\n",
            "[1.41 2.02 0.1  0.72]\n",
            "[3.   1.11 0.05 0.07]\n",
            "[1.46 0.   0.83 1.93]\n",
            "[2.45 1.02 0.   0.75]\n",
            "[1.7  2.27 0.   0.23]\n",
            "[2.03 1.27 0.62 0.3 ]\n",
            "[0.78 2.55 0.04 0.84]\n",
            "[0.88 2.3  0.2  0.83]\n",
            "[1.3  2.07 0.18 0.65]\n",
            "[1.28 1.83 0.57 0.53]\n",
            "[2.25 1.47 0.04 0.43]\n",
            "[2.02 1.06 0.58 0.53]\n",
            "[0.84 2.79 0.02 0.53]\n",
            "[3.38 0.44 0.31 0.04]\n",
            "[2.04 0.48 1.57 0.07]\n",
            "[3.79 0.27 0.   0.11]\n",
            "[3.36 0.21 0.01 0.56]\n",
            "[1.4  1.86 0.11 0.77]\n",
            "[4.03 0.   0.09 0.  ]\n",
            "[1.65 0.61 1.76 0.09]\n",
            "[0.71 2.48 0.03 0.89]\n",
            "[2.14 1.2  0.37 0.4 ]\n",
            "[1.42 0.51 2.1  0.07]\n",
            "[2.13 1.5  0.05 0.42]\n",
            "[2.45 1.26 0.01 0.37]\n",
            "[2.57 1.52 0.   0.  ]\n",
            "[2.65 1.06 0.04 0.33]\n",
            "[2.32 0.04 0.04 1.67]\n",
            "[2.35 1.28 0.03 0.41]\n",
            "[0.12 2.26 0.9  0.77]\n",
            "[2.28 1.55 0.16 0.06]\n",
            "[1.68 1.51 0.51 0.35]\n",
            "[1.12 2.12 0.1  0.69]\n",
            "[2.78 0.58 0.64 0.04]\n",
            "[1.38 1.87 0.12 0.65]\n",
            "[1.22 0.28 2.46 0.04]\n",
            "[2.15 1.2  0.07 0.59]\n",
            "[0.92 1.78 0.92 0.37]\n",
            "[2.67 0.89 0.05 0.37]\n",
            "[2.08 1.35 0.   0.54]\n",
            "[2.1  1.36 0.06 0.4 ]\n",
            "[1.18 1.96 0.08 0.7 ]\n",
            "[1.97 0.76 1.07 0.11]\n",
            "[2.29 1.17 0.01 0.42]\n",
            "[1.33 1.71 0.13 0.73]\n",
            "[0.67 0.49 2.62 0.11]\n",
            "[1.53 1.61 0.06 0.67]\n",
            "[1.15 2.09 0.   0.64]\n",
            "[0.93 1.94 0.31 0.7 ]\n",
            "[0.1  0.   3.77 0.  ]\n",
            "[2.12 1.14 0.1  0.51]\n",
            "[2.48 0.65 0.03 0.69]\n",
            "[0.16 1.89 1.12 0.68]\n",
            "[0.87 1.57 1.05 0.35]\n",
            "[2.12 1.44 0.22 0.06]\n",
            "[2.21 0.96 0.54 0.13]\n",
            "[2.26 0.48 0.81 0.27]\n",
            "[1.06 1.93 0.41 0.43]\n",
            "[1.44 1.37 0.73 0.27]\n",
            "[1.49 1.58 0.1  0.61]\n",
            "[1.14 1.91 0.27 0.46]\n",
            "[2.4  1.03 0.   0.36]\n",
            "[1.82 1.24 0.47 0.25]\n",
            "[1.4  1.4  0.1  0.87]\n",
            "[1.98 1.47 0.   0.32]\n",
            "[2.03 1.56 0.   0.17]\n",
            "[1.98 0.88 0.59 0.32]\n",
            "[1.37 2.   0.14 0.22]\n",
            "[0.96 2.   0.21 0.56]\n",
            "[1.3  0.77 1.54 0.11]\n",
            "[1.93 1.58 0.   0.19]\n",
            "[0.58 2.48 0.04 0.59]\n",
            "[1.49 0.73 1.38 0.1 ]\n",
            "[1.3  1.51 0.27 0.61]\n",
            "[1.59 1.61 0.08 0.41]\n",
            "[0.   0.   3.67 0.  ]\n",
            "[2.13 1.18 0.01 0.35]\n",
            "[1.65 1.22 0.   0.79]\n",
            "[1.87 1.13 0.55 0.1 ]\n",
            "[2.53 0.81 0.06 0.24]\n",
            "[2.33 0.97 0.   0.35]\n",
            "[0.71 1.8  0.4  0.74]\n",
            "[2.08 1.09 0.15 0.33]\n",
            "[2.23 0.68 0.66 0.06]\n",
            "[0.6  2.46 0.05 0.52]\n",
            "[0.05 0.   0.64 2.93]\n",
            "[1.78 1.42 0.05 0.38]\n",
            "[2.08 0.83 0.46 0.25]\n",
            "[1.28 1.61 0.15 0.57]\n",
            "[1.93 1.22 0.03 0.44]\n",
            "[2.05 1.4  0.   0.16]\n",
            "[2.02 1.17 0.   0.42]\n",
            "[1.61 1.5  0.1  0.39]\n",
            "[2.38 0.67 0.46 0.1 ]\n",
            "[2.18 1.02 0.03 0.37]\n",
            "[2.01 1.35 0.06 0.16]\n",
            "[1.57 1.79 0.   0.2 ]\n",
            "[1.56 1.4  0.07 0.5 ]\n",
            "[1.23 1.77 0.05 0.49]\n",
            "[1.66 1.58 0.12 0.18]\n",
            "[1.9  1.13 0.1  0.41]\n",
            "[1.98 1.14 0.01 0.41]\n",
            "[2.14 1.08 0.02 0.29]\n",
            "[0.71 2.4  0.02 0.4 ]\n",
            "[1.96 1.33 0.   0.23]\n",
            "[2.14 1.21 0.01 0.17]\n",
            "[2.66 0.5  0.05 0.3 ]\n",
            "[1.22 1.66 0.27 0.38]\n",
            "[2.11 0.94 0.12 0.34]\n",
            "[1.17 0.5  1.75 0.08]\n",
            "[2.84 0.39 0.03 0.24]\n",
            "[1.64 0.38 1.42 0.06]\n",
            "[2.2  0.97 0.02 0.31]\n",
            "[0.59 1.83 0.73 0.35]\n",
            "[0.59 2.36 0.04 0.51]\n",
            "[1.94 1.22 0.02 0.31]\n",
            "[2.09 1.02 0.04 0.32]\n",
            "[2.11 1.01 0.01 0.35]\n",
            "[2.26 0.89 0.   0.3 ]\n",
            "[0.88 1.75 0.1  0.72]\n",
            "[0.   0.   3.44 0.  ]\n",
            "[2.39 0.73 0.03 0.29]\n",
            "[1.55 1.27 0.33 0.29]\n",
            "[1.34 1.54 0.17 0.38]\n",
            "[1.82 1.07 0.06 0.47]\n",
            "[1.13 2.07 0.   0.22]\n",
            "[0.86 0.   2.55 0.02]\n",
            "[1.75 1.2  0.02 0.43]\n",
            "[1.73 0.69 0.59 0.4 ]\n",
            "[0.46 2.28 0.05 0.61]\n",
            "[1.56 1.47 0.19 0.17]\n",
            "[2.03 1.03 0.   0.32]\n",
            "[1.08 1.35 0.48 0.47]\n",
            "[1.43 0.94 0.74 0.27]\n",
            "[2.47 0.76 0.   0.13]\n",
            "[1.9  0.67 0.73 0.06]\n",
            "[0.65 1.61 0.82 0.28]\n",
            "[1.63 1.53 0.   0.18]\n",
            "[1.9  1.14 0.01 0.29]\n",
            "[0.   0.99 2.32 0.02]\n",
            "[1.45 1.29 0.12 0.46]\n",
            "[1.44 1.01 0.57 0.3 ]\n",
            "[1.15 1.17 0.76 0.24]\n",
            "[1.47 1.39 0.03 0.43]\n",
            "[1.99 1.05 0.05 0.22]\n",
            "[1.5  1.28 0.05 0.46]\n",
            "[0.8  1.92 0.06 0.5 ]\n",
            "[2.13 0.92 0.   0.23]\n",
            "[1.89 1.05 0.02 0.31]\n",
            "[1.36 1.13 0.46 0.32]\n",
            "[0.5  1.59 0.31 0.87]\n",
            "[0.25 0.19 2.78 0.04]\n",
            "[0.95 1.3  0.77 0.22]\n",
            "[0.88 2.11 0.   0.23]\n",
            "[1.27 1.33 0.12 0.51]\n",
            "[2.33 0.3  0.   0.59]\n",
            "[0.03 0.   3.18 0.  ]\n",
            "[1.72 1.33 0.   0.16]\n",
            "[0.73 0.1  2.35 0.02]\n",
            "[2.26 0.72 0.12 0.1 ]\n",
            "[1.76 1.21 0.07 0.16]\n",
            "[1.35 0.6  0.8  0.44]\n",
            "[1.48 1.01 0.04 0.66]\n",
            "[0.   0.   3.19 0.  ]\n",
            "[2.15 0.77 0.01 0.26]\n",
            "[1.78 1.12 0.09 0.19]\n",
            "[1.18 0.87 0.93 0.2 ]\n",
            "[1.52 1.08 0.1  0.47]\n",
            "[1.86 1.02 0.   0.29]\n",
            "[[29.08  3.58  6.81  0.77]\n",
            " [15.85 12.88  3.79  3.31]\n",
            " [15.75 11.01  3.28  2.96]\n",
            " ...\n",
            " [ 1.18  0.87  0.93  0.2 ]\n",
            " [ 1.52  1.08  0.1   0.47]\n",
            " [ 1.86  1.02  0.    0.29]]\n",
            "Media calculada: [3.16208817 2.01772622 0.89064965 0.62990719]\n",
            "Desviación estandar calculada: [3.10581848 1.73308636 1.38327683 0.8040492 ]\n",
            "[[ 8.34495385  0.90144024  4.27922322  0.17423412]\n",
            " [ 4.08520715  6.26758945  2.09600152  3.33324478]\n",
            " [ 4.05300952  5.18858955  1.72731176  2.89794804]\n",
            " ...\n",
            " [-0.63818545 -0.6622441   0.0284472  -0.53467772]\n",
            " [-0.5287135  -0.54107299 -0.57157731 -0.19887737]\n",
            " [-0.41924155 -0.57569331 -0.64386942 -0.42274427]]\n"
          ]
        }
      ],
      "source": [
        "# llama featureNormalize con los datos cargados\n",
        "for i in range (m):\n",
        "  print(X[i])\n",
        "X_norm, mu, sigma = featureNormalize(X)\n",
        "\n",
        "print(X)\n",
        "print('Media calculada:', mu)\n",
        "print('Desviación estandar calculada:', sigma)\n",
        "print(X_norm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60-ukRpMixeD"
      },
      "source": [
        "Despues de `featureNormalize` la funcion es provada, se añade el temino de interseccion a `X_norm`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 322,
      "metadata": {
        "id": "6d3wMkViixeD"
      },
      "outputs": [],
      "source": [
        "# Añade el termino de interseccion a X\n",
        "# (Columna de unos para X0)\n",
        "X = np.concatenate([np.ones((m, 1)), X_norm], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 323,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUMhtErHixeD",
        "outputId": "a495343c-0719-422d-ee36-36b61550d059"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.          8.34495385  0.90144024  4.27922322  0.17423412]\n",
            " [ 1.          4.08520715  6.26758945  2.09600152  3.33324478]\n",
            " [ 1.          4.05300952  5.18858955  1.72731176  2.89794804]\n",
            " ...\n",
            " [ 1.         -0.63818545 -0.6622441   0.0284472  -0.53467772]\n",
            " [ 1.         -0.5287135  -0.54107299 -0.57157731 -0.19887737]\n",
            " [ 1.         -0.41924155 -0.57569331 -0.64386942 -0.42274427]]\n"
          ]
        }
      ],
      "source": [
        "print(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYKmdg1vixeE"
      },
      "source": [
        "<a id=\"section5\"></a>\n",
        "### 2.2 Descenso por el gradiente\n",
        "\n",
        "En el ejemplo anterior se implemento el descenso por el gradiente para un problema de regresion univariable. La unica diferencia es que ahora existe una caracteristica adicional en la matriz $X$. La función de hipótesis y la regla de actualización del descenso del gradiente por lotes permanecen sin cambios.\n",
        "\n",
        "La implementacion de las funciones `computeCostMulti` y `gradientDescentMulti` son similares a la funcion de costo y función de descenso por el gradiente de la regresión lineal multiple es similar al de la regresion lineal multivariable. Es importante garantizar que el codigo soporte cualquier numero de caracteristicas y esten bien vectorizadas.\n",
        "\n",
        "Se puede utilizar `shape`, propiedad de los arrays `numpy`, para identificar cuantas caracteristicas estan consideradas en el dataset.\n",
        "\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "**Nota de implementación:** En el caso de multivariables, la función de costo puede se escrita considerando la forma vectorizada de la siguiente manera:\n",
        "\n",
        "$$ J(\\theta) = \\frac{1}{2m}(X\\theta - \\vec{y})^T(X\\theta - \\vec{y}) $$\n",
        "\n",
        "donde:\n",
        "\n",
        "$$ X = \\begin{pmatrix}\n",
        "          - (x^{(1)})^T - \\\\\n",
        "          - (x^{(2)})^T - \\\\\n",
        "          \\vdots \\\\\n",
        "          - (x^{(m)})^T - \\\\ \\\\\n",
        "        \\end{pmatrix} \\qquad \\mathbf{y} = \\begin{bmatrix} y^{(1)} \\\\ y^{(2)} \\\\ \\vdots \\\\ y^{(m)} \\\\\\end{bmatrix}$$\n",
        "\n",
        "La version vectorizada es eficiente cuando se trabaja con herramientas de calculo numericos computacional como `numpy`. \n",
        "</div>\n",
        "\n",
        "<a id=\"computeCostMulti\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 324,
      "metadata": {
        "id": "Z8Vfnu1KixeF"
      },
      "outputs": [],
      "source": [
        "def computeCostMulti(X, y, theta):\n",
        "    # Inicializa algunos valores utiles\n",
        "    m = y.shape[0] # numero de ejemplos de entrenamiento\n",
        "    \n",
        "    J = 0\n",
        "    \n",
        "    h = np.dot(X, theta)\n",
        "    \n",
        "    J = (1/(2 * m)) * np.sum(np.square(np.dot(X, theta) - y))\n",
        "    \n",
        "    return J\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 325,
      "metadata": {
        "id": "Z2pHrF-zixeF"
      },
      "outputs": [],
      "source": [
        "def gradientDescentMulti(X, y, theta, alpha, num_iters):\n",
        "    \n",
        "    # Inicializa algunos valores \n",
        "    m = y.shape[0] # numero de ejemplos de entrenamiento\n",
        "    \n",
        "    # realiza una copia de theta, el cual será acutalizada por el descenso por el gradiente\n",
        "    theta = theta.copy()\n",
        "    \n",
        "    J_history = []\n",
        "    \n",
        "    for i in range(num_iters):\n",
        "        theta = theta - (alpha / m) * (np.dot(X, theta) - y).dot(X)\n",
        "        J_history.append(computeCostMulti(X, y, theta))\n",
        "    \n",
        "    return theta, J_history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y6Mnr1OixeF"
      },
      "source": [
        "#### 3.2.1 Seleccionando coheficientes de aprendizaje\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 326,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "TtB6P_D8ixeG",
        "outputId": "44ef8fef-81dd-4391-83fa-d615e5ef6ab3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.          8.34495385  0.90144024  4.27922322  0.17423412]\n",
            " [ 1.          4.08520715  6.26758945  2.09600152  3.33324478]\n",
            " [ 1.          4.05300952  5.18858955  1.72731176  2.89794804]\n",
            " ...\n",
            " [ 1.         -0.63818545 -0.6622441   0.0284472  -0.53467772]\n",
            " [ 1.         -0.5287135  -0.54107299 -0.57157731 -0.19887737]\n",
            " [ 1.         -0.41924155 -0.57569331 -0.64386942 -0.42274427]]\n",
            "theta calculado por el descenso por el gradiente: [0.8906496504732236 -3.833601792744542e-06 3.461304819234941e-05\n",
            " 1.3832612946366152 -2.612131131342344e-05]\n",
            "La salud fetal (usando el descenso por el gradiente): 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Elegir algun valor para alpha (probar varias alternativas)\n",
        "print(X)\n",
        "alpha = 0.02\n",
        "num_iters = 1000\n",
        "\n",
        "# inicializa theta y ejecuta el descenso por el gradiente\n",
        "theta = np.zeros(5)\n",
        "theta, J_history = gradientDescentMulti(X, y, theta, alpha, num_iters)\n",
        "\n",
        "# Grafica la convergencia del costo\n",
        "pyplot.plot(np.arange(len(J_history)), J_history, lw=2)\n",
        "pyplot.xlabel('Numero de iteraciones')\n",
        "pyplot.ylabel('Costo J')\n",
        "\n",
        "# Muestra los resultados del descenso por el gradiente\n",
        "print('theta calculado por el descenso por el gradiente: {:s}'.format(str(theta)))\n",
        "\n",
        "# Estimar el precio para una casa de 1650 sq-ft, con 3 dormitorios\n",
        "X_array = [1, 10.58760203, 12.44014015,  2.06589141,  8.79869606]\n",
        "X_array[1:5] = (X_array[1:5] - mu) / sigma\n",
        "price = np.dot(X_array, theta)   # Se debe cambiar esto\n",
        "\n",
        "print('La salud fetal (usando el descenso por el gradiente): {:.0f}'.format(price))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 327,
      "metadata": {
        "id": "lPn4NezUixeG"
      },
      "outputs": [],
      "source": [
        "X_array = [1, 10.58760203, 12.44014015,  2.06589141,  8.79869606]\n",
        "X_array[1:5] = (X_array[1:5] - mu) / sigma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 328,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1zgpbf9ixeG",
        "outputId": "48dcf2ac-649f-4585-887c-9fc57c2b85c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.3908396200101434, 6.013787984646985, 0.8496070558563731, 10.159563430472605]"
            ]
          },
          "metadata": {},
          "execution_count": 328
        }
      ],
      "source": [
        "X_array[1:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBYG2VZGixeH"
      },
      "source": [
        "<a id=\"section7\"></a>\n",
        "### 2.3 Ecuacion de la Normal\n",
        "\n",
        "Una manera de calcular rapidamente el modelo de una regresion lineal es:\n",
        "\n",
        "$$ \\theta = \\left( X^T X\\right)^{-1} X^T\\vec{y}$$\n",
        "\n",
        "Utilizando esta formula no requiere que se escale ninguna caracteristica, y se obtendra una solucion exacta con un solo calculo: no hay “bucles de convergencia” como en el descenso por el gradiente. \n",
        "\n",
        "Primero se recargan los datos para garantizar que las variables no esten modificadas. Recordar que no es necesario escalar las caracteristicas, se debe agregar la columna de unos a la matriz $X$ para tener el termino de intersección($\\theta_0$). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 329,
      "metadata": {
        "id": "8Gn2aeGUixeH"
      },
      "outputs": [],
      "source": [
        "# Cargar datos\n",
        "data = pd.read_csv((\"/content/drive/MyDrive/dataset/vgsales.csv\"), delimiter=',', skiprows=1)\n",
        "data= np.array(data)\n",
        "X = np.column_stack((data[:431,2:2],data[:431,4:4],data[:431,6:10]))\n",
        "\n",
        "\n",
        "y = data[:431, 8]\n",
        "m = y.size\n",
        "X = np.concatenate([np.ones((m, 1)), X], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 330,
      "metadata": {
        "id": "Ggl3eon1ixeH"
      },
      "outputs": [],
      "source": [
        "def normalEqn(X, y):\n",
        "  \n",
        "    theta = np.zeros(X.shape[1])\n",
        "    \n",
        "    theta = np.dot(np.dot(np.linalg.inv(np.dot(X.T,X)),X.T),y)\n",
        "    \n",
        "    return theta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 331,
      "metadata": {
        "id": "PnGJwc7wixeH",
        "outputId": "852d77b0-1ae9-45ef-fff9-75a58570e732",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "UFuncTypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-331-083440bfa069>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Calcula los parametros con la ecuación de la normal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalEqn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Muestra los resultados optenidos a partir de la aplicación de la ecuación de la normal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Theta calculado a partir de la ecuación de la normal: {:s}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-330-a0359970a8f2>\u001b[0m in \u001b[0;36mnormalEqn\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUFuncTypeError\u001b[0m: Cannot cast ufunc 'inv' input from dtype('O') to dtype('float64') with casting rule 'same_kind'"
          ]
        }
      ],
      "source": [
        "# Calcula los parametros con la ecuación de la normal\n",
        "theta = normalEqn(X, y);\n",
        "\n",
        "# Muestra los resultados optenidos a partir de la aplicación de la ecuación de la normal\n",
        "print('Theta calculado a partir de la ecuación de la normal: {:s}'.format(str(theta)));\n",
        "\n",
        "# Estimar el precio para una casa de superficie de 1650 sq-ft y tres dormitorios\n",
        "\n",
        "X_array = [1, 10.58760203, 12.44014015,  2.06589141,  8.79869606]\n",
        "price = np.dot(X_array, theta) \n",
        "\n",
        "print('Precio predecido para una cada de superficie de 1650 sq-ft y 3 dormitorios (usando la ecuación de la normal): ${:.0f}'.format(price))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "89c1e5897a05c230b641cbe6795c273f19c63c261829cbeaac49beeeb28f3eb6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}